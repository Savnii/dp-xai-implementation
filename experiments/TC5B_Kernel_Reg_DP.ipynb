{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395bcf9-a856-4bc1-b7c9-bee5f21d0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "FILE_SUFFIX = \"DP1\"\n",
    "\n",
    "print(\"Step 1: Loading the dataset.\")\n",
    "df = pd.read_csv('../datasets/drug_overdose.csv')\n",
    "\n",
    "print(\"Step 2: Cleaning the data and engineering features.\")\n",
    "\n",
    "df = df[df['Indicator'] == 'Number of Drug Overdose Deaths'].copy()\n",
    "\n",
    "df.dropna(subset=['Data Value'], inplace=True)\n",
    "\n",
    "cols_to_drop = ['State', 'Period', 'Footnote', 'Footnote Symbol',\n",
    "                'Predicted Value', 'Percent Complete', 'Percent Pending Investigation']\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "print(\"Step 3: Separating features (X) and target (y).\")\n",
    "y = df['Data Value']\n",
    "X = df[['State Name', 'Year']]\n",
    "\n",
    "print(\"Step 4: Identifying and preprocessing numerical and categorical columns.\")\n",
    "categorical_cols = ['State Name']\n",
    "numeric_cols = ['Year']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X).toarray()\n",
    "y_scaler = StandardScaler()\n",
    "y_processed = y_scaler.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "joblib.dump(preprocessor.named_transformers_['num'], f\"artifacts/feature_scaler{FILE_SUFFIX}.joblib\")\n",
    "print(f\"Saved numeric feature scaler to artifacts/feature_scaler{FILE_SUFFIX}.joblib\")\n",
    "\n",
    "joblib.dump(preprocessor.named_transformers_['cat'], f\"artifacts/onehot_encoder{FILE_SUFFIX}.joblib\")\n",
    "print(f\"Saved one-hot encoder to artifacts/onehot_encoder{FILE_SUFFIX}.joblib\")\n",
    "\n",
    "joblib.dump(y_scaler, f\"artifacts/target_scaler{FILE_SUFFIX}.joblib\")\n",
    "print(f\"Saved target scaler to artifacts/target_scaler{FILE_SUFFIX}.joblib\")\n",
    "\n",
    "print(\"\\nStep 5: Combining and saving the cleaned data to a CSV file.\")\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "cleaned_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "cleaned_df['scaled_data_value'] = y_processed\n",
    "\n",
    "cleaned_df.to_csv(f'cleaned_overdose_data{FILE_SUFFIX}.csv', index=False)\n",
    "print(f\"File 'cleaned_overdose_data{FILE_SUFFIX}.csv' has been saved successfully.\")\n",
    "\n",
    "print(\"\\nData preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be9422-7b92-4402-b812-a414d405de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import os\n",
    "\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print(f\"\\n--- STARTING TEST CASE 5: KernelExplainer on DP-Teacher ---\")\n",
    "FILE_SUFFIX = \"DP1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading DP1 data...\")\n",
    "df = pd.read_csv(f'cleaned_overdose_data{FILE_SUFFIX}.csv')\n",
    "X = df.drop(columns='scaled_data_value').values.astype(np.float32)\n",
    "feature_names = df.drop(columns='scaled_data_value').columns.tolist()\n",
    "INPUT_DIM = X.shape[1]\n",
    "\n",
    "print(\"Loading DP-SGD Teacher model...\")\n",
    "model = RegressionNN(INPUT_DIM).to(device)\n",
    "weights_path = f\"artifacts/dpsgd_regression_model{FILE_SUFFIX}.pt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "def predict_wrapper(x_numpy):\n",
    "    x_tensor = torch.tensor(x_numpy).to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x_tensor).cpu().numpy()\n",
    "    return preds\n",
    "\n",
    "print(\"Creating K-Means background data for SHAP...\")\n",
    "\n",
    "X_train_summary = shap.kmeans(X, 50)\n",
    "print(\"Running shap.KernelExplainer...\")\n",
    "explainer = shap.KernelExplainer(predict_wrapper, X_train_summary)\n",
    "shap_values = explainer.shap_values(X[:50]) # Explain the first 50 samples\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim > 2:\n",
    "    shap_values = np.squeeze(shap_values)\n",
    "\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "\n",
    "print(\"\\n**Average absolute SHAP values (KernelExplainer - DP-Teacher):**\")\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print(shap_df.head())\n",
    "\n",
    "SAVE_PATH = f'shap_feature_importance_KERNEL_DP1_Teacher.csv'\n",
    "shap_df.to_csv(SAVE_PATH, index=False)\n",
    "print(f\"\\nSaved KernelExplainer SHAP feature importance to '{SAVE_PATH}'.\")\n",
    "print(\"\\n--- DP-Teacher Model (KernelExplainer) Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ffab7-d507-40e1-8887-1d6ec2da549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import os\n",
    "\n",
    "class StudentNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "print(f\"\\n--- STARTING TEST CASE 5: KernelExplainer on KD-Student ---\")\n",
    "FILE_SUFFIX = \"DP1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading DP1 data...\")\n",
    "df = pd.read_csv(f'cleaned_overdose_data{FILE_SUFFIX}.csv')\n",
    "X = df.drop(columns='scaled_data_value').values.astype(np.float32)\n",
    "feature_names = df.drop(columns='scaled_data_value').columns.tolist()\n",
    "INPUT_DIM = X.shape[1]\n",
    "\n",
    "print(\"Loading KD Student model...\")\n",
    "model = StudentNN(INPUT_DIM).to(device)\n",
    "weights_path = f\"artifacts/kd_student_model{FILE_SUFFIX}.pt\"\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "def predict_wrapper(x_numpy):\n",
    "    x_tensor = torch.tensor(x_numpy).to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x_tensor).cpu().numpy()\n",
    "    return preds\n",
    "\n",
    "print(\"Creating K-Means background data for SHAP...\")\n",
    "X_summary = shap.kmeans(X, 50) \n",
    "\n",
    "print(\"Running shap.KernelExplainer...\")\n",
    "explainer = shap.KernelExplainer(predict_wrapper, X_summary)\n",
    "shap_values = explainer.shap_values(X[:50])\n",
    "\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "if shap_values.ndim > 2:\n",
    "    shap_values = np.squeeze(shap_values)\n",
    "\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
    "\n",
    "print(\"\\n**Average absolute SHAP values (KernelExplainer - KD-Student):**\")\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'mean_abs_shap': mean_abs_shap\n",
    "}).sort_values('mean_abs_shap', ascending=False)\n",
    "\n",
    "print(shap_df.head())\n",
    "\n",
    "SAVE_PATH = f'shap_feature_importance_KERNEL_DP1_Student.csv'\n",
    "shap_df.to_csv(SAVE_PATH, index=False)\n",
    "print(f\"\\nSaved KernelExplainer SHAP feature importance to '{SAVE_PATH}'.\")\n",
    "print(\"\\n--- KD-Student Model (KernelExplainer) Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
